# Fine-tuning Data Curation for LLM-based Question-Answering Using LoRA/QLoRA for a Specific Domain

This repo contains the INFO 621 final project of Our (Pineapple Programmers) team, which includes three team members: Xiaoqin Fu, Subhrajeet Ghosh, and Usama Ahmed. In this work, we propose a fine-tuning data curation method for answering questions of a specific domain: building energy sector.

The building sector accounts for one-third of U.S. carbon emissions, making decarbonization a critical priority. Effective data management is essential for this effort, as vast amounts of building-related information—such as codes, standards, and operational data—must be analyzed to inform decision-making. Recent advancements in AI and large language models (LLMs) have the ability to process, interpret, and generate text, making them effective for accessing relevant insights. However, foundational LLMs (e.g., GPT, LLaMA, T5, BERT) rely on general datasets that lack the specialized knowledge required for building decarbonization. Fine-tuning these models with domain-specific data presents a promising solution, though challenges remain in addressing missing, duplicate, inconsistent, or unstructured information.

We selected the EnergyPlus Engineering Reference document as our input due to its comprehensive and detailed documentation of the EnergyPlus simulation application, which serves as a strong example of professional software documentation important for building decarbonization. This reference provides in-depth information and knowledge on the underlying principles, mathematical models, and algorithms used in EnergyPlus, which are essential for accurate building energy modeling. Utilizing this resource ensures that our search/recommendation system is based on validated and reliable methodologies, enhancing the credibility and precision of the system responses.

## Install Requirements

## Data Preparation (Part 1)

### Step 1: 
 The raw data: EngineeringReference.pdf
### Step 2: 

### Step 3: 

## LLM Execution (Part 2)

### Step 1: 

### Step 2: 

### Step 3: 
